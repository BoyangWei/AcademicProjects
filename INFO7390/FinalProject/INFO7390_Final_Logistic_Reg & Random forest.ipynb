{"cells":[{"cell_type":"code","source":["import numpy as np\nimport pandas as pd\n\nAP_data = pd.DataFrame(columns=[\"match_id\",\"hero_id\",\"player_slot\",\"radiant_win_res\"])\n#113 heros\nMatch_data_columns = range(1,114)\nMatch_data = pd.DataFrame(columns=Match_data_columns)\n\nprint(Match_data)"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["%fs ls /FileStore/tables/"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["df_data = pd.read_csv(\"/dbfs/FileStore/tables/match_hero_pick_50000.csv\", header=0)\nprint(df_data)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["count = 1\nMatch_Result = pd.DataFrame(columns=[\"radiant_win_res\"])\nfor index, row in df_data.iterrows():\n  match_id = row['match_id']\n  hero_id = row['hero_id']\n  player_slot = row['player_slot']\n  radiant_win = row['radiant_win']\n  if radiant_win == True:\n      radiant_win_res = True\n  else:\n      radiant_win_res = False\n  Match_Result.loc[match_id] = radiant_win_res\n  if count % 10 == 1:\n      Match_data.loc[match_id] = np.zeros(113)\n  if count % 10 < 6:\n      Match_data.loc[match_id][hero_id] = 1\n  else:\n      Match_data.loc[match_id][hero_id] = -1\n  #Match_data.loc[match_id]['label'] = radiant_win_res\n  count += 1"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["Match_data['radiant_win'] = Match_Result.astype(int)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["Match_data.describe()"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["from pyspark.ml import Pipeline\nfrom pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n\ncategoricalColumns = []\n#categoricalColumns = map(str, range(1,227))\n#categoricalColumns.remove('24')\n#categoricalColumns.remove('108')\n#categoricalColumns.remove('113')\n#categoricalColumns.remove('137')\n#categoricalColumns.remove('221')\n#categoricalColumns.remove('226')\n#print(categoricalColumns)\n\nstages = []\nfor categoricalCol in categoricalColumns:\n  # Category Indexing with StringIndexer\n  stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol+\"Index\")\n  # Use OneHotEncoder to convert categorical variables into binary SparseVectors\n  encoder = OneHotEncoder(inputCol=categoricalCol+\"Index\", outputCol=categoricalCol+\"classVec\")\n  # Add stages.  These are not run here, but will run all at once later on.\n  stages += [stringIndexer, encoder]"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["label_stringIdx = StringIndexer(inputCol = \"radiant_win\", outputCol = \"label\")\nstages += [label_stringIdx]"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["numericCols = map(str, range(1,114))\nassemblerInputs = map(lambda c: c + \"classVec\", categoricalColumns) + numericCols\nassembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\nstages += [assembler]"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["spark_df = sqlContext.createDataFrame(Match_data)\n\npipeline = Pipeline(stages=stages)\npipelineModel = pipeline.fit(spark_df)\ndataset = pipelineModel.transform(spark_df)\n\ndisplay(dataset)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["(trainingData, testData) = dataset.randomSplit([0.9, 0.1], seed = 333)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["from pyspark.ml.classification import LogisticRegression\n\n# Create initial LogisticRegression model\nlr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=10)\n\n# Train model with Training Data\nlrModel = lr.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["predictions = lrModel.transform(testData)"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\n\n# Evaluate model\nevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\nevaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\n# Create ParamGrid for Cross Validation\nparamGrid = (ParamGridBuilder()\n             .addGrid(lr.regParam, [0.1, 0.5, 1])\n             .addGrid(lr.elasticNetParam, [0, 0.5, 1])\n             .addGrid(lr.maxIter, [5])\n             .build())"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["# Create 10-fold CrossValidator\ncv = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=10)\ncvModel = cv.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["predictions = cvModel.transform(testData)\nevaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["from pyspark.ml.regression import GBTRegressor\n# Takes the \"features\" column and learns to predict \"cnt\"\ngbt = GBTRegressor(labelCol=\"radiant_win\")"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["from pyspark.ml.feature import VectorAssembler, VectorIndexer\nfeaturesCols = map(str, range(1,114))\n#featuresCols.remove('cnt')\n# This concatenates all feature columns into a single feature vector in a new column \"rawFeatures\".\nvectorAssembler = VectorAssembler(inputCols=featuresCols, outputCol=\"rawFeatures\")\n# This identifies categorical features and indexes them.\nvectorIndexer = VectorIndexer(inputCol=\"rawFeatures\", outputCol=\"features\", maxCategories=10)"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\nfrom pyspark.ml.evaluation import RegressionEvaluator\n# Define a grid of hyperparameters to test:\n#  - maxDepth: max depth of each decision tree in the GBT ensemble\n#  - maxIter: iterations, i.e., number of trees in each GBT ensemble\n# In this example notebook, we keep these values small.  In practice, to get the highest accuracy, you would likely want to try deeper trees (10 or higher) and more trees in the ensemble (>100).\nparamGrid = ParamGridBuilder()\\\n  .addGrid(gbt.maxDepth, [2, 5])\\\n  .addGrid(gbt.maxIter, [10, 100])\\\n  .build()\n# We define an evaluation metric.  This tells CrossValidator how well we are doing by comparing the true labels with predictions.\nevaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=gbt.getLabelCol(), predictionCol=gbt.getPredictionCol())\n# Declare the CrossValidator, which runs model tuning for us.\ncv = CrossValidator(estimator=gbt, evaluator=evaluator, estimatorParamMaps=paramGrid)"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["from pyspark.ml import Pipeline\npipeline = Pipeline(stages=[vectorAssembler, vectorIndexer, cv])\n(trainingData_DT, testData_DT) = spark_df.randomSplit([0.9, 0.1], seed = 333)"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["pipelineModel = pipeline.fit(trainingData_DT)\npredictions = pipelineModel.transform(testData_DT)"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["rmse = evaluator.evaluate(predictions)\nprint \"RMSE on our test set: %g\" % rmse"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["from pyspark.ml.classification import RandomForestClassifier\n\n# Create an initial RandomForest model.\nrf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n\n# Train model with Training Data\nrfModel = rf.fit(trainingData)\npredictions = rfModel.transform(testData)"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\n\n# Evaluate model\nevaluator = BinaryClassificationEvaluator()\nevaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\nparamGrid = (ParamGridBuilder()\n             .addGrid(rf.maxDepth, [2, 4, 6])\n             .addGrid(rf.maxBins, [20, 60])\n             .addGrid(rf.numTrees, [5, 20])\n             .build())"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["cv = CrossValidator(estimator=rf, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\ncvModel = cv.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["predictions = cvModel.transform(testData)\nevaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":28}],"metadata":{"name":"INFO7390_Final_Logistic_Reg & Random forest","notebookId":3750532894677254},"nbformat":4,"nbformat_minor":0}
